{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook demos varios differential operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with our differential operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dusk.script import *\n",
    "\n",
    "\n",
    "@stencil\n",
    "def gradient(f: Field[Edge], nx: Field[Edge], ny: Field[Edge], L: Field[Edge], A: Field[Cell], edge_orientation: Field[Cell > Edge], \n",
    "                f_x: Field[Cell], f_y: Field[Cell]):\n",
    "  with levels_downward:\n",
    "    # replace by computation of gradient\n",
    "    f_x = 0\n",
    "    f_y = 0\n",
    "\n",
    "@stencil\n",
    "def divergence(u: Field[Edge], v: Field[Edge], nx: Field[Edge], ny: Field[Edge], L: Field[Edge], A: Field[Cell], edge_orientation: Field[Cell > Edge],\n",
    "                  uv_div: Field[Cell]):\n",
    "  with levels_downward:\n",
    "    # replace by computation of divergence\n",
    "    uv_div = 0\n",
    "\n",
    "@stencil\n",
    "def curl(u: Field[Edge], v: Field[Edge], nx: Field[Edge], ny: Field[Edge], dualL: Field[Edge], dualA: Field[Vertex], edge_orientation: Field[Vertex > Edge],\n",
    "            uv_curl: Field[Vertex]):\n",
    "  with levels_downward:\n",
    "    # replace by computation of curl\n",
    "    uv_curl = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use dusk's Python API to convert the stencils to SIR. This API can also invoke dawn to compile SIR to C++:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dusk.transpile import callables_to_pyast, pyast_to_sir, sir_to_json\n",
    "with open(\"diff_ops.sir\", \"w+\") as f:\n",
    "    sir = pyast_to_sir(callables_to_pyast([gradient, divergence, curl]))\n",
    "    f.write(sir_to_json(sir))\n",
    "!/usr/local/dawn/bin/dawn-opt diff_ops.sir | /usr/local/dawn/bin/dawn-codegen -b naive-ico -o diff_ops_cxx-naive.cpp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated C++ code also requires a driver which is already setup for this demo. With the driver code we can generate an executable `runner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, its up to you which differentail operator you want to run and check. Simply launch `runner gradient`, `runner divergence` or `runner curl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./runner gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides ensuring the error norms L1, L2 and L infinity are small (they should all be well below 0.1), you can also have a look at some test functions and their differentials. Again, you can use `check gradient`, `check divergence` or `check curl`. Please make sure that you ran the appropriate differential operator beforhand using the `runner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run checker.py gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "output_auto_scroll": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}